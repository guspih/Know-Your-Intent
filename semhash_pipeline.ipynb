{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking using SemHash on NLU Evaluation Corpora\n",
    "\n",
    "This notebook benchmarks the results on the 3 NLU Evaluation Corpora:\n",
    "1. Ask Ubuntu Corpus\n",
    "2. Chatbot Corpus\n",
    "3. Web Application Corpus\n",
    "\n",
    "\n",
    "More information about the dataset is available here: \n",
    "\n",
    "https://github.com/sebischair/NLU-Evaluation-Corpora\n",
    "\n",
    "\n",
    "* Semantic Hashing is used as a featurizer. The idea is taken from the paper:\n",
    "\n",
    "https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/\n",
    "\n",
    "* Benchmarks are performed on the same train and test datasets used by the other benchmarks performed in the past. One important paper that benchmarks the datasets mentioned above on some important platforms (Dialogflow, Luis, Watson and RASA) is : \n",
    "\n",
    "http://workshop.colips.org/wochat/@sigdial2017/documents/SIGDIAL22.pdf\n",
    "\n",
    "* Furthermore, Botfuel made another benchmarks with more platforms (Recast, Snips and their own) and results can be found here: \n",
    "\n",
    "https://github.com/Botfuel/benchmark-nlp-2018\n",
    "\n",
    "* The blogposts about the benchmarks done in the past are available at : \n",
    "\n",
    "https://medium.com/botfuel/benchmarking-intent-classification-services-june-2018-eb8684a1e55f\n",
    "\n",
    "https://medium.com/snips-ai/an-introduction-to-snips-nlu-the-open-source-library-behind-snips-embedded-voice-platform-b12b1a60a41a\n",
    "\n",
    "* To be very fair on our benchmarks and results, we used the same train and test set used by the other benchmarks and no cross validation or stratified splits were used. The test data was not used in any way to improve the results. The dataset used can be found here:\n",
    "\n",
    "https://github.com/Botfuel/benchmark-nlp-2018/tree/master/results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "import spacy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy english dataset needs to be present. It can be downloaded using the following command:\n",
    "\n",
    "python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intent_dict_AskUbuntu = {\"Make Update\":0, \"Setup Printer\":1, \"Shutdown Computer\":2, \"Software Recommendation\":3, \"None\":4}\n",
    "intent_dict_Chatbot = {\"DepartureTime\":0, \"FindConnection\":1}\n",
    "intent_dict_WebApplications = {\"Download Video\":0, \"Change Password\":1, \"None\":2, \"Export Data\":3, \"Sync Accounts\":4,\n",
    "                  \"Filter Spam\":5, \"Find Alternative\":6, \"Delete Account\":7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "benchmark_dataset = 'AskUbuntu' #choose from 'AskUbuntu', 'Chatbot' or 'WebApplications'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_train = \"datasets/KL/\" + benchmark_dataset + \"/train.csv\"\n",
    "filename_test = \"datasets/KL/\" + benchmark_dataset + \"/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_CSV_datafile(filename):    \n",
    "    X = []\n",
    "    y = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            X.append(row[0])\n",
    "            if benchmark_dataset == 'AskUbuntu':\n",
    "                y.append(intent_dict_AskUbuntu[row[1]])\n",
    "            elif benchmark_dataset == 'Chatbot':\n",
    "                y.append(intent_dict_Chatbot[row[1]])\n",
    "            else:\n",
    "                y.append(intent_dict_WebApplications[row[1]])           \n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_raw, y_train_raw = read_CSV_datafile(filename = filename_train)\n",
    "X_test_raw, y_test_raw = read_CSV_datafile(filename = filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples: \n",
      " ['Are there any Keyboard Shortcuts to Shutdown?', 'Shutdown after a certain time', 'Shutdown problem in Ubuntu 16.04', 'How do I fix a shutdown problem?'] \n",
      "\n",
      "\n",
      "Class Labels: \n",
      " [2, 2, 2, 2] \n",
      "\n",
      "\n",
      "Size of Training Data: 53\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data samples: \\n\",X_train_raw[-5:-1], \"\\n\\n\")\n",
    "\n",
    "print(\"Class Labels: \\n\", y_train_raw[-5:-1], \"\\n\\n\")\n",
    "\n",
    "print(\"Size of Training Data: {}\".format(len(X_train_raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    \"\"\"\n",
    "    Returns a list of strings containing each token in `sentence`\n",
    "    \"\"\"\n",
    "    #return [i for i in re.split(r\"([-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=])\",\n",
    "    #                            doc) if i != '' and i != ' ' and i != '\\n']\n",
    "    tokens = []\n",
    "    doc = nlp.tokenizer(doc)\n",
    "    for token in doc:\n",
    "        tokens.append(token.text)\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    clean_tokens = []\n",
    "    doc = nlp(doc)\n",
    "    for token in doc:\n",
    "        if not token.is_stop:\n",
    "            clean_tokens.append(token.lemma_)\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "def semhash_tokenizer(text):\n",
    "    tokens = text.split(\" \")\n",
    "    final_tokens = []\n",
    "    for unhashed_token in tokens:\n",
    "        hashed_token = \"#{}#\".format(unhashed_token)\n",
    "        final_tokens += [''.join(gram)\n",
    "                         for gram in list(find_ngrams(list(hashed_token), 3))]\n",
    "    return final_tokens\n",
    "\n",
    "def semhash_corpus(corpus):\n",
    "    new_corpus = []\n",
    "    for sentence in corpus:\n",
    "        sentence = preprocess(sentence)\n",
    "        tokens = semhash_tokenizer(sentence)\n",
    "        new_corpus.append(\" \".join(map(str,tokens)))\n",
    "    return new_corpus\n",
    "\n",
    "X_train_raw = semhash_corpus(X_train_raw)\n",
    "X_test_raw = semhash_corpus(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#ho how ow# #re rec eco cor ord rd# #sc scr cre ree een en# #?#',\n",
       " '#ho how ow# #-P -PR PRO RON ON- N-# #hi hig igh ghl hli lig igh ght ht# #an ann nno not ota tat ate te# #pd pdf df# #?#',\n",
       " '#be be# #wo wor ort rth th# #up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #lt lts ts# #13 13. 3.0 .04 04#',\n",
       " '#up upg pgr gra rad ade de# #12 12. 2.0 .04 04# #64 64# #bi bit it#',\n",
       " '#ho how ow# #up upg pgr gra rad ade de# #ub ubu bun unt ntu tu# #14 14. 4.0 .04 04. 4.1 .1# #14 14. 4.0 .04 04. 4.2 .2# #?#']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vectorizer(corpus, preprocessor=None, tokenizer=None):\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "    vectorizer.fit(corpus)\n",
    "    return vectorizer, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "              print_report=True, feature_names=None, print_top10=False,\n",
    "              print_cm=True):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    #print(\"Accuracy: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate([\"Make Update\", \"Setup Printer\", \"Shutdown Computer\",\"Software Recommendation\", \"None\"]):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join([feature_names[i] for i in top10]))))\n",
    "        print()\n",
    "\n",
    "    if print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    # make some plots\n",
    "    indices = np.arange(len(results))\n",
    "\n",
    "    results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "    clf_names, score, training_time, test_time = results\n",
    "    training_time = np.array(training_time) / np.max(training_time)\n",
    "    test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Score\")\n",
    "    plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "    plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "             color='c')\n",
    "    plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "    plt.yticks(())\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplots_adjust(left=.25)\n",
    "    plt.subplots_adjust(top=.95)\n",
    "    plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "    for i, c in zip(indices, clf_names):\n",
    "        plt.text(-.3, i, c)\n",
    "    plt.savefig(\"./results_AskUbuntu.png\", format=\"png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_training():\n",
    "    vectorizer, feature_names = get_vectorizer(X_train_raw, preprocessor=preprocess, tokenizer=tokenize)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train_raw).toarray()\n",
    "    X_test = vectorizer.transform(X_test_raw).toarray()\n",
    "            \n",
    "    return X_train, y_train_raw, X_test, y_test_raw, feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Split 0\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 3 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1]\n",
      "Train Size: 53\n",
      "Test Size: 109\n",
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 0.016s\n",
      "test time:  0.002s\n",
      "accuracy:   0.908\n",
      "dimensionality: 3737\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.95      1.00      0.97        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.94      0.80      0.86        40\n",
      "                   None       0.38      0.60      0.46         5\n",
      "\n",
      "              micro avg       0.91      0.91      0.91       109\n",
      "              macro avg       0.84      0.88      0.85       109\n",
      "           weighted avg       0.92      0.91      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 32  5]\n",
      " [ 0  0  0  2  3]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchknn\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'n_neighbors': [3, 4, 5, 6]}, pre_dispatch='2*n_jobs',\n",
      "       refit=True, return_train_score='warn', scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.310s\n",
      "test time:  0.030s\n",
      "accuracy:   0.817\n",
      "classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.86      0.97      0.91        37\n",
      "          Setup Printer       0.91      0.77      0.83        13\n",
      "      Shutdown Computer       0.56      1.00      0.72        14\n",
      "Software Recommendation       0.94      0.72      0.82        40\n",
      "                   None       0.00      0.00      0.00         5\n",
      "\n",
      "              micro avg       0.82      0.82      0.82       109\n",
      "              macro avg       0.65      0.69      0.66       109\n",
      "           weighted avg       0.81      0.82      0.80       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  0  1  0  0]\n",
      " [ 3 10  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  8 29  0]\n",
      " [ 0  1  2  2  0]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchmlp\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'hidden_layer_sizes': [(100, 50), (300, 100), (300, 200, 100)]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 17.257s\n",
      "test time:  0.004s\n",
      "accuracy:   0.908\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       0.88      1.00      0.93        14\n",
      "Software Recommendation       0.90      0.90      0.90        40\n",
      "                   None       1.00      0.20      0.33         5\n",
      "\n",
      "              micro avg       0.91      0.91      0.91       109\n",
      "              macro avg       0.92      0.81      0.81       109\n",
      "           weighted avg       0.91      0.91      0.90       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  0  1  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  1  0 36  0]\n",
      " [ 0  0  1  3  1]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
      "              max_iter=None, n_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "              random_state=None, shuffle=True, tol=None,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.121s\n",
      "test time:  0.001s\n",
      "accuracy:   0.917\n",
      "dimensionality: 3737\n",
      "density: 0.807011\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.97      0.95        37\n",
      "          Setup Printer       0.87      1.00      0.93        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.92      0.88      0.90        40\n",
      "                   None       0.67      0.40      0.50         5\n",
      "\n",
      "              micro avg       0.92      0.92      0.92       109\n",
      "              macro avg       0.88      0.85      0.85       109\n",
      "           weighted avg       0.91      0.92      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  1  0  0  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  1  0 35  1]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchRF\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'n_estimators': [50, 60, 70], 'min_samples_leaf': [1, 11]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:626: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.176s\n",
      "test time:  0.006s\n",
      "accuracy:   0.917\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.95      0.97      0.96        37\n",
      "          Setup Printer       0.92      0.85      0.88        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.88      0.93      0.90        40\n",
      "                   None       0.67      0.40      0.50         5\n",
      "\n",
      "              micro avg       0.92      0.92      0.92       109\n",
      "              macro avg       0.88      0.83      0.85       109\n",
      "           weighted avg       0.91      0.92      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  0  0  1  0]\n",
      " [ 0 11  0  2  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  0  0 37  1]\n",
      " [ 0  1  0  2  2]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.010s\n",
      "test time:  0.002s\n",
      "accuracy:   0.917\n",
      "dimensionality: 3737\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.97      0.95        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.88      0.89        40\n",
      "                   None       0.67      0.40      0.50         5\n",
      "\n",
      "              micro avg       0.92      0.92      0.92       109\n",
      "              macro avg       0.88      0.85      0.86       109\n",
      "           weighted avg       0.91      0.92      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  0  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  1  0 35  1]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=50, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.060s\n",
      "test time:  0.003s\n",
      "accuracy:   0.881\n",
      "dimensionality: 3737\n",
      "density: 0.414075\n",
      "\n",
      "classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.89      0.92      0.91        37\n",
      "          Setup Printer       0.86      0.92      0.89        13\n",
      "      Shutdown Computer       0.93      1.00      0.97        14\n",
      "Software Recommendation       0.86      0.90      0.88        40\n",
      "                   None       0.00      0.00      0.00         5\n",
      "\n",
      "              micro avg       0.88      0.88      0.88       109\n",
      "              macro avg       0.71      0.75      0.73       109\n",
      "           weighted avg       0.84      0.88      0.86       109\n",
      "\n",
      "confusion matrix:\n",
      "[[34  1  0  2  0]\n",
      " [ 0 12  0  1  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  1  0 36  0]\n",
      " [ 1  0  1  3  0]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.021s\n",
      "test time:  0.002s\n",
      "accuracy:   0.908\n",
      "dimensionality: 3737\n",
      "density: 0.004817\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.95      0.97      0.96        37\n",
      "          Setup Printer       0.80      0.92      0.86        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.92      0.85      0.88        40\n",
      "                   None       0.60      0.60      0.60         5\n",
      "\n",
      "              micro avg       0.91      0.91      0.91       109\n",
      "              macro avg       0.85      0.87      0.86       109\n",
      "           weighted avg       0.91      0.91      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  1  0  0  0]\n",
      " [ 0 12  0  1  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  2  0 34  2]\n",
      " [ 0  0  0  2  3]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=50, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.182s\n",
      "test time:  0.002s\n",
      "accuracy:   0.899\n",
      "dimensionality: 3737\n",
      "density: 0.384426\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.89      0.90        37\n",
      "          Setup Printer       1.00      1.00      1.00        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.92      0.88      0.90        40\n",
      "                   None       0.38      0.60      0.46         5\n",
      "\n",
      "              micro avg       0.90      0.90      0.90       109\n",
      "              macro avg       0.84      0.87      0.85       109\n",
      "           weighted avg       0.91      0.90      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[33  0  0  1  3]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  0 35  2]\n",
      " [ 0  0  0  2  3]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=50, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.178s\n",
      "test time:  0.002s\n",
      "accuracy:   0.899\n",
      "dimensionality: 3737\n",
      "density: 0.387851\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.97      0.86      0.91        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       0.78      1.00      0.88        14\n",
      "Software Recommendation       0.90      0.93      0.91        40\n",
      "                   None       0.67      0.40      0.50         5\n",
      "\n",
      "              micro avg       0.90      0.90      0.90       109\n",
      "              macro avg       0.85      0.84      0.83       109\n",
      "           weighted avg       0.90      0.90      0.90       109\n",
      "\n",
      "confusion matrix:\n",
      "[[32  0  3  2  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 1  1  0 37  1]\n",
      " [ 0  0  1  2  2]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.001s\n",
      "test time:  0.003s\n",
      "accuracy:   0.908\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.97      0.95        37\n",
      "          Setup Printer       0.77      0.77      0.77        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.93      0.91        40\n",
      "                   None       1.00      0.40      0.57         5\n",
      "\n",
      "              micro avg       0.91      0.91      0.91       109\n",
      "              macro avg       0.92      0.81      0.84       109\n",
      "           weighted avg       0.91      0.91      0.90       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  1  0  0  0]\n",
      " [ 1 10  0  2  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 37  0]\n",
      " [ 0  1  0  2  2]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.002s\n",
      "accuracy:   0.899\n",
      "dimensionality: 3737\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.81      1.00      0.90        13\n",
      "      Shutdown Computer       0.88      1.00      0.93        14\n",
      "Software Recommendation       0.92      0.88      0.90        40\n",
      "                   None       1.00      0.20      0.33         5\n",
      "\n",
      "              micro avg       0.90      0.90      0.90       109\n",
      "              macro avg       0.91      0.80      0.80       109\n",
      "           weighted avg       0.91      0.90      0.89       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  1  1  0  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  2  0 35  0]\n",
      " [ 0  0  1  3  1]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.005s\n",
      "test time:  0.007s\n",
      "accuracy:   0.917\n",
      "dimensionality: 3737\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.87      1.00      0.93        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.90      0.90        40\n",
      "                   None       1.00      0.40      0.57         5\n",
      "\n",
      "              micro avg       0.92      0.92      0.92       109\n",
      "              macro avg       0.94      0.85      0.87       109\n",
      "           weighted avg       0.92      0.92      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  1  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  1  0 36  0]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        max_features=None, no...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.029s\n",
      "test time:  0.001s\n",
      "accuracy:   0.890\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.94      0.89      0.92        37\n",
      "          Setup Printer       0.80      0.92      0.86        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.89      0.85      0.87        40\n",
      "                   None       0.57      0.80      0.67         5\n",
      "\n",
      "              micro avg       0.89      0.89      0.89       109\n",
      "              macro avg       0.84      0.89      0.86       109\n",
      "           weighted avg       0.90      0.89      0.89       109\n",
      "\n",
      "confusion matrix:\n",
      "[[33  2  0  2  0]\n",
      " [ 0 12  0  1  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 34  3]\n",
      " [ 0  0  0  1  4]]\n",
      "\n",
      "================================================================================\n",
      "KMeans\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=0, tol=0.0001, verbose=0)\n",
      "train time: 0.083s\n",
      "test time:  0.005s\n",
      "accuracy:   0.404\n",
      "classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusgru\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.37      0.97      0.54        37\n",
      "          Setup Printer       0.67      0.62      0.64        13\n",
      "      Shutdown Computer       0.00      0.00      0.00        14\n",
      "Software Recommendation       0.00      0.00      0.00        40\n",
      "                   None       0.00      0.00      0.00         5\n",
      "\n",
      "              micro avg       0.40      0.40      0.40       109\n",
      "              macro avg       0.21      0.32      0.24       109\n",
      "           weighted avg       0.21      0.40      0.26       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  1  0  0  0]\n",
      " [ 5  8  0  0  0]\n",
      " [13  1  0  0  0]\n",
      " [39  1  0  0  0]\n",
      " [ 4  1  0  0  0]]\n",
      "\n",
      "================================================================================\n",
      "LogisticRegression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 0.013s\n",
      "test time:  0.002s\n",
      "accuracy:   0.908\n",
      "dimensionality: 3737\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.87      1.00      0.93        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.88      0.89        40\n",
      "                   None       0.67      0.40      0.50         5\n",
      "\n",
      "              micro avg       0.91      0.91      0.91       109\n",
      "              macro avg       0.87      0.84      0.85       109\n",
      "           weighted avg       0.90      0.91      0.90       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  1  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  1  0 35  1]\n",
      " [ 0  0  0  3  2]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i_s, split in enumerate(range(1)):\n",
    "    print(\"Evaluating Split {}\".format(i_s))\n",
    "    X_train, y_train, X_test, y_test, feature_names = data_for_training()\n",
    "    print(X_train[:,5])\n",
    "    target_names = [\"Make Update\", \"Setup Printer\", \"Shutdown Computer\",\"Software Recommendation\", \"None\"]\n",
    "    #target_names = [\"Download Video\", \"Change Password\", \"None\", \"Export Data\", \"Sync Accounts\",\n",
    "    #              \"Filter Spam\", \"Find Alternative\", \"Delete Account\"]\n",
    "    print(\"Train Size: {}\\nTest Size: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    results = []\n",
    "    #alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "    parameters_mlp={'hidden_layer_sizes':[(100,50), (300, 100),(300,200,100)]}\n",
    "    parameters_RF={ \"n_estimators\" : [50,60,70],\n",
    "           \"min_samples_leaf\" : [1, 11]}\n",
    "    k_range = list(range(3,7))\n",
    "    parameters_knn = {'n_neighbors':k_range}\n",
    "    knn=KNeighborsClassifier(n_neighbors=5)\n",
    "    for clf, name in [  \n",
    "            (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "            (GridSearchCV(knn,parameters_knn, cv=5),\"gridsearchknn\"),\n",
    "            #(Perceptron(n_iter=50), \"Perceptron\"),\n",
    "            (GridSearchCV(MLPClassifier(activation='tanh'),parameters_mlp, cv=5),\"gridsearchmlp\"),\n",
    "           # (MLPClassifier(hidden_layer_sizes=(100, 50), activation=\"logistic\", max_iter=300), \"MLP\"),\n",
    "            #(MLPClassifier(hidden_layer_sizes=(300, 100, 50), activation=\"logistic\", max_iter=500), \"MLP\"),\n",
    "           # (MLPClassifier(hidden_layer_sizes=(300, 100, 50), activation=\"tanh\", max_iter=500), \"MLP\"),\n",
    "            (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=1), \"kNN\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=3), \"kNN\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=5), \"kNN\"),\n",
    "            #(KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "            (GridSearchCV(RandomForestClassifier(n_estimators=10),parameters_RF, cv=5),\"gridsearchRF\")\n",
    "            #(RandomForestClassifier(n_estimators=10), \"Random forest\"),\n",
    "            #(RandomForestClassifier(n_estimators=50), \"Random forest\")\n",
    "    ]:\n",
    "           \n",
    "        print('=' * 80)\n",
    "        print(name)\n",
    "        results.append(benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "       # print('parameters')\n",
    "       # print(clf.grid_scores_[0])\n",
    "        #print('CV Validation Score')\n",
    "       # print(clf.grid_scores_[0].cv_validation_scores)\n",
    "       # print('Mean Validation Score')\n",
    "       # print(clf.grid_scores_[0].mean_validation_score)\n",
    "       # grid_mean_scores = [result.mean_validation_score for result in clf.grid_scores_]\n",
    "       # print(grid_mean_scores)\n",
    "       # plt.plot(k_range, grid_mean_scores)\n",
    "       # plt.xlabel('Value of K for KNN')\n",
    "       # plt.ylabel('Cross-Validated Accuracy')\n",
    "\n",
    "    #parameters_Linearsvc = [{'C': [1, 10], 'gamma': [0.1,1.0]}]\n",
    "    for penalty in [\"l2\", \"l1\"]:\n",
    "        print('=' * 80)\n",
    "        print(\"%s penalty\" % penalty.upper())\n",
    "        # Train Liblinear model\n",
    "        #grid=(GridSearchCV(LinearSVC,parameters_Linearsvc, cv=10),\"gridsearchSVC\")\n",
    "        #results.append(benchmark(LinearSVC(penalty=penalty), X_train, y_train, X_test, y_test, target_names,\n",
    "                                # feature_names=feature_names))\n",
    "        results.append(benchmark(LinearSVC(penalty=penalty, dual=False,tol=1e-3),\n",
    "                                 X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "\n",
    "        # Train SGD model\n",
    "        results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                               penalty=penalty),\n",
    "                                 X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "\n",
    "    # Train SGD with Elastic Net penalty\n",
    "    print('=' * 80)\n",
    "    print(\"Elastic-Net penalty\")\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=\"elasticnet\"),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    # Train NearestCentroid without threshold\n",
    "    print('=' * 80)\n",
    "    print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "    results.append(benchmark(NearestCentroid(),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    # Train sparse Naive Bayes classifiers\n",
    "    print('=' * 80)\n",
    "    print(\"Naive Bayes\")\n",
    "    results.append(benchmark(MultinomialNB(alpha=.01),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    results.append(benchmark(BernoulliNB(alpha=.01),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    print('=' * 80)\n",
    "    print(\"LinearSVC with L1-based feature selection\")\n",
    "    # The smaller C, the stronger the regularization.\n",
    "    # The more regularization, the more sparsity.\n",
    "    \n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "    results.append(benchmark(Pipeline([\n",
    "                                  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                                                  tol=1e-3))),\n",
    "                                  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "   # print(grid.grid_scores_)\n",
    "   #KMeans clustering algorithm \n",
    "    print('=' * 80)\n",
    "    print(\"KMeans\")\n",
    "    results.append(benchmark(KMeans(n_clusters=2, init='k-means++', max_iter=300,\n",
    "                verbose=0, random_state=0, tol=1e-4),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('=' * 80)\n",
    "    print(\"LogisticRegression\")\n",
    "    #kfold = model_selection.KFold(n_splits=2, random_state=0)\n",
    "    #model = LinearDiscriminantAnalysis()\n",
    "    results.append(benchmark(LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    \n",
    "    plot_results(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
